{"cells":[{"cell_type":"markdown","source":["#Give me some credit predictive model\n## Data set from:\n- https://www.kaggle.com/c/GiveMeSomeCredit \n\nraul.arrabales - Apr. 17"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SQLContext, Row\nfrom pyspark.sql.types import *\n# sqlContext = SQLContext(sc)\n# sqlContext = SQLContext.getOrCreate(SparkContext.getOrCreate())"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["dbutils.fs.ls('/FileStore/tables/')"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["Dataset:\ncs-training.csv available as: dbfs:/FileStore/tables/ca964k591492704726010"],"metadata":{}},{"cell_type":"code","source":["# Load de CSV data into a RDD and count (150.000 records expected)\ntraining_set_csv = sc.textFile(\"dbfs:/FileStore/tables/ca964k591492704726010\")\ntraining_set_csv.count()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Explore a few lines\ntraining_set_csv.take(5)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Get header with field names\nheader = training_set_csv.first()\nheader"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Remove CSV header from the RDD\ncreditHeader = training_set_csv.filter(lambda l: \"SeriousDlqin2yrs\" in l)\ncreditHeader.count()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# After removing the header we should have 150.000 rows\ntraining_set_csv = training_set_csv.subtract(creditHeader)\ntraining_set_csv.count()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# Fields in the training set\nfields = [StructField(field_name, StringType(), True) for field_name in header.split(',')]\nfields"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# Number of fields in training set\nlen(fields)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Amend field data types\nfields[0].name = \"_id\" #  = StructField( \"_id\", LongType(), True)\nfields[0].dataType = LongType()\n\nfields[1] =StructField(\n  \"label\", DoubleType(), False,\n  {\"ml_attr\": {\n      \"name\": \"label\",\n      \"type\": \"nominal\", \n      \"vals\": [\"0.0\", \"1.0\"]\n    }}\n)\n\nfields[2].dataType = FloatType()\nfields[3].dataType = IntegerType()\nfields[4].dataType = IntegerType()\nfields[5].dataType = FloatType()\nfields[6].dataType = FloatType()\nfields[7].dataType = IntegerType()\nfields[8].dataType = IntegerType()\nfields[9].dataType = IntegerType()\nfields[10].dataType = IntegerType()\nfields[11].dataType = IntegerType()\nfields"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# See how's the RDD format now, there're some NA values\ntraining_set_csv.take(4)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["rowsWithNA = training_set_csv.filter(lambda l: \"NA\" in l)\nrowsWithNA.count()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["training_set_csv = training_set_csv.subtract(rowsWithNA)\ntraining_set_csv.count()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["<pre>\nVariable Name\t\t                        Type\nSeriousDlqin2yrs\t \t                    Y/N\nRevolvingUtilizationOfUnsecuredLines\t\tpercentage\nage\t\t                                    integer\nNumberOfTime30-59DaysPastDueNotWorse\t    integer\nDebtRatio\t                                percentage\nMonthlyIncome\t\t                        real\nNumberOfOpenCreditLinesAndLoans\t            integer\nNumberOfTimes90DaysLate\t\t                integer\nNumberRealEstateLoansOrLines                integer\nNumberOfTime60-89DaysPastDueNotWorse\t\tinteger\nNumberOfDependents\t                        integer\n</pre>"],"metadata":{}},{"cell_type":"code","source":["temp = training_set_csv.map(lambda k: k.split(\",\")).map(lambda p: (long(p[0]), float(p[1]), float(p[2]), int(p[3]), int(p[4]) , float(p[5]), float(p[6]) , int(p[7]), int(p[8]), int(p[9]), int(p[10]), int(p[11])))"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["temp.take(4)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# Schema for the table\nschema = StructType(fields)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# Create the dataframe\ntraining_df = sqlContext.createDataFrame(temp,schema)\ntraining_df.count()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["training_df.take(4)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["# Check dataframe types\ntraining_df.dtypes"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# Check dataframe schema\ntraining_df.printSchema()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# Missing values?\ntraining_df.filter(training_df.NumberRealEstateLoansOrLines == '').count()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# Checking number of delinquents\ntraining_df.groupBy(\"SeriousDlqin2yrs\").count().show()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["# Register a temp table to be used with the SQL API\ntraining_df.registerTempTable(\"traindata\")"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["# Let's change some column names\ntraining_df = training_df.withColumnRenamed('NumberOfTime60-89DaysPastDueNotWorse', 'Num6089').withColumnRenamed('NumberRealEstateLoansOrLines', 'NumLoans').withColumnRenamed('RevolvingUtilizationOfUnsecuredLines','Revolving').withColumnRenamed('NumberOfTime30-59DaysPastDueNotWorse','Num3059').withColumnRenamed('SeriousDlqin2yrs', 'label')"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["training_df.describe()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# Using a selection from the Spark Dataframe as a pandas dataframe\nimport pandas as pd\nmatureDelinquents = training_df.filter(\"label = 1 and age > 50\").toPandas()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["matureDelinquents.head()"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["# Using Spark ML (not MLLIB) for building a Random Forest model\n# from pyspark.mllib.tree import RandomForest, RandomForestModel\n# from pyspark.mllib.util import MLUtils\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.feature import IndexToString, StringIndexer, VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# Index labels, adding metadata to the label column.\n# Fit on whole dataset to include all labels in index.\nlabelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(training_df)\nlabelIndexer.labels"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["plan_indexer = StringIndexer(inputCol = 'intl_plan', outputCol = 'intl_plan_indexed')"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["# Create the feature column\nassembler = VectorAssembler(\n  inputCols = ['Revolving', 'age', 'Num3059', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumLoans', 'Num6089', 'NumberOfDependents'],\n  outputCol = 'features')"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["# Training the model\nclassifier = RandomForestClassifier(labelCol = 'label', featuresCol = 'features')\npipeline = Pipeline(stages=[labelIndexer, assembler, classifier])\nmodel = pipeline.fit(training_df)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["# Evaluating the model\n# Need to do that over a test set, not the same training set. \nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n \npredictions = model.transform(training_df)\nevaluator = BinaryClassificationEvaluator()\nauroc = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["predictions.take(3)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["auroc"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":39}],"metadata":{"name":"GiveMeCredit","notebookId":2563354865905080},"nbformat":4,"nbformat_minor":0}
